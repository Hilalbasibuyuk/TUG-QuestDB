# TUG-QuestDB
## QuestDB nedir?
QuestDB diÄŸer veri tabanlarÄ±ndan Ã§ok daha farklÄ± bir yapÄ±ya sahiptir ve gelecekte yaygÄ±nlaÅŸmasÄ± muhtemeldir.Geleneksel veritabanlarÄ±nÄ±n aksine, zaman serisi verilerinin benzersiz Ã¶zelliklerini (Ã§ok sayÄ±da satÄ±r ekleme, sorgulama ve sÄ±ralama) en iyi ÅŸekilde ele almak iÃ§in Ã¶zel bir mimariye sahiptir. QuestDB, Ã¶zellikle zaman serisi (time-series) verileri iÃ§in tasarlanmÄ±ÅŸ, yÃ¼ksek performanslÄ±, aÃ§Ä±k kaynaklÄ± bir veritabanÄ±dÄ±r. Temel odak noktasÄ±, finansal piyasa verileri, IoT sensÃ¶r okumalarÄ±, uygulama metrikleri, telemetri ve olay izleme (log kayÄ±tlarÄ±) gibi saniyede milyonlarca veri noktasÄ±nÄ±n alÄ±ndÄ±ÄŸÄ± ve hÄ±zlÄ± bir ÅŸekilde sorgulandÄ±ÄŸÄ± senaryolardÄ±r. 


###  QuestDB'nin temel yapÄ± taÅŸlarÄ±:
- **Kolon BazlÄ± Depolama (Columnar Storage):** Bu mimaride veriler satÄ±r satÄ±r deÄŸil, sÃ¼tun sÃ¼tun saklanÄ±r. Geleneksel bir veritabanÄ±nda bir satÄ±rÄ±n tÃ¼m verileri (Ã¶rneÄŸin, bir sensÃ¶rden gelen tarih, sÄ±caklÄ±k, basÄ±nÃ§) tek bir blokta saklanÄ±r. QuestDB'de ise her bir sÃ¼tunun verileri ayrÄ± ayrÄ± depolanÄ±r. Disk yapÄ±sÄ±nda, her tablo bir klasÃ¶r olarak saklanÄ±r. Her sÃ¼tun bir dosyadÄ±r.  Ã–rnek: "Ortalama sÄ±caklÄ±k nedir?" gibi bir sorgu yaptÄ±ÄŸÄ±nÄ±zda, veritabanÄ± sadece temperature.bin dosyasÄ±nÄ± okur. TÃ¼m satÄ±rlarÄ± (cihazID, nem gibi ilgisiz verileri) okumak zorunda kalmaz. Bu, disk I/O iÅŸlemlerini bÃ¼yÃ¼k Ã¶lÃ§Ã¼de azaltÄ±r.
- **Zaman BazlÄ± BÃ¶lÃ¼mleme (Partitioning):** QuestDB, verileri zamana gÃ¶re otomatik olarak bÃ¶lÃ¼mlere (partition) ayÄ±rÄ±r. Bu, veritabanÄ±nÄ±n en gÃ¼Ã§lÃ¼ Ã¶zelliklerinden biridir. Veriler, belirli zaman aralÄ±klarÄ±na gÃ¶re (Ã¶rneÄŸin, gÃ¼nlÃ¼k, aylÄ±k veya yÄ±llÄ±k) ayrÄ± dosyalarda saklanÄ±r. Yani zaman damgasÄ±na gÃ¶re otomatik bÃ¶lÃ¼mlere ayrÄ±lÄ±r (Ã¶r. gÃ¼nlÃ¼k, aylÄ±k, yÄ±llÄ±k). Bu sayede sorgular sadece ilgili bÃ¶lÃ¼mlere bakar.
- **SQL UyumluluÄŸu:** Sorgular iÃ§in standart SQL sÃ¶zdizimi kullanÄ±r. Ã–zel bir sorgu dili yoktur, bildiÄŸimiz SQL ile Ã§alÄ±ÅŸÄ±lÄ±r. Sadece zaman serisi analizi iÃ§in Ã¶zel fonksiyonlar ve sÃ¶zdizimi ekler(SAMPLE BY, LATEST ON,ASOF JOIN gibi). Bu, onu Ã¶ÄŸrenmesi ve kullanmasÄ± kolay bir araÃ§ yapar.
- **YÃ¼ksek Verim (Throughput) ve DÃ¼ÅŸÃ¼k Gecikme (Latency):** Tek bir sunucuda saniyede milyonlarca satÄ±rlÄ±k veri ekleme kapasitesine sahiptir. Veriler milisaniyeler iÃ§inde sorgulanabilir hale gelir. 



### Ana Ã¶zellikleri ÅŸunlardÄ±r:
- Ã‡ok hÄ±zlÄ± yazma ve okuma (milyonlarca kayÄ±t/saniye iÅŸleyebilir).
- Kolay entegrasyon (Postgres wire protocol, REST API, InfluxDB line protocol desteÄŸi).
- Yeni kayÄ±tlar her zaman sona eklenir. Bu da diskte sÄ±ralÄ± yazmaya izin verir â†’ SSD/HDD iÃ§in maksimum hÄ±z.
- BÃ¼yÃ¼k miktarda alÄ±m iÅŸleme ve verimlilik
- YÃ¼ksek performanslÄ± veri Ã§oÄŸaltma ve sÄ±ra dÄ±ÅŸÄ± dizinleme
- YÃ¼ksek veri kardinalitesi performans dÃ¼ÅŸÃ¼ÅŸÃ¼ne yol aÃ§mayacaktÄ±r.(Kardinalite, bir kÃ¼meyi oluÅŸturan farklÄ± deÄŸer sayÄ±sÄ±nÄ± gÃ¶steren bir veri niteliÄŸidir. YÃ¼ksek kardinaliteli verilere sahip olmak, veri kÃ¼mesinde Ã§ok sayÄ±da benzersiz deÄŸer olduÄŸu anlamÄ±na gelir.)
- DonanÄ±m verimliliÄŸi (SensÃ¶rler ve Raspberry Pi dahil olmak Ã¼zere Ã§ok kÃ¼Ã§Ã¼k donanÄ±mlarda gÃ¼Ã§lÃ¼, maliyet tasarrufu saÄŸlayan performans.)


!! **InfluxDB**, InfluxData ÅŸirketi tarafÄ±ndan geliÅŸtirilen bir zaman serisi veritabanÄ±dÄ±r. Operasyon izleme, uygulama Ã¶lÃ§Ã¼mleri, Nesnelerin Ä°nterneti sensÃ¶r verileri ve gerÃ§ek zamanlÄ± analiz gibi alanlarda zaman serisi verilerinin depolanmasÄ± ve alÄ±nmasÄ± iÃ§in kullanÄ±lÄ±r. AyrÄ±ca Grafitten veri iÅŸleme desteÄŸi de vardÄ±r.



**QuestDB'de yÃ¼ksek kardinalite ile baÅŸa Ã§Ä±kma**
AslÄ±nda, yÃ¼ksek kardinalitede asÄ±l zorluk veritabanlarÄ±nÄ±n verileri depolama ve iÅŸleme biÃ§iminden kaynaklanmaktadÄ±r. Ã–rneÄŸin, InfluxDB ve diÄŸer bazÄ± zaman serisi veritabanlarÄ±nda, her zaman serisi kendi dosya grubunda ayrÄ± ayrÄ± saklanÄ±r. AynÄ± tabloda binlerce veya milyonlarca zaman serisi depolandÄ±ÄŸÄ±nda, yazma ve tam tarama sorgu performansÄ± Ã¶nemli Ã¶lÃ§Ã¼de dÃ¼ÅŸer. Bunun nedeni, bu yÃ¼ksek kardinaliteli senaryolarda disk yazma ve okuma iÅŸlemlerinin Ã§ok daha az sÄ±ralÄ± Ã¶rÃ¼ntÃ¼ye sahip olmasÄ±dÄ±r. SonuÃ§ olarak, bellek gereksinimleri benzersiz zaman serisi sayÄ±sÄ±yla birlikte katlanarak artar.

QuestDB, her sÃ¼tunun kendi yerel biÃ§iminde ayrÄ± ayrÄ± depolandÄ±ÄŸÄ± yoÄŸun, sÃ¼tun tabanlÄ± bir depolama modeli kullanÄ±r . TÃ¼m satÄ±rlar zamana gÃ¶re sÄ±ralanÄ±r ve sÄ±ralÄ± Ã¶rÃ¼ntÃ¼leri korumak iÃ§in zaman tabanlÄ± bÃ¶lÃ¼mlere ayrÄ±lÄ±r. Bu, QuestDB'nin yÃ¼ksek kardinalite de dahil olmak Ã¼zere tÃ¼m senaryolarda iyi bir performans seviyesini korumasÄ±nÄ± saÄŸlar.


### En bÃ¼yÃ¼k hitleri ÅŸunlardÄ±r:
- **SAMPLE BY** Verileri bir yÄ±ldan bir mikrosaniyeye kadar belirli bir zaman aralÄ±ÄŸÄ±na gÃ¶re parÃ§alara Ã¶zetler
- **WHERE IN** Zaman aralÄ±klarÄ±nÄ± Ã¶zlÃ¼ aralÄ±klara sÄ±kÄ±ÅŸtÄ±rmak
- **LATEST ON** Bir tablodaki birden fazla serideki en son deÄŸerler iÃ§in
- **ASOF JOIN** YakÄ±nlÄ±ÄŸa dayalÄ± olarak bir seri arasÄ±ndaki zaman damgalarÄ±nÄ± iliÅŸkilendirmek iÃ§in; ekstra endekslere gerek yok
- PerformansÄ± optimize etmek iÃ§in karmaÅŸÄ±k sorgu sonuÃ§larÄ±nÄ± Ã¶nceden hesaplamak ve otomatik olarak yenilemek iÃ§in MaddeleÅŸtirilmiÅŸ GÃ¶rÃ¼nÃ¼mler


<img width="914" height="644" alt="image" src="https://github.com/user-attachments/assets/8e75123d-8d95-4a98-ae7d-13514ea74c97" />



Ancak daha az dayanÄ±klÄ± donanÄ±mlarda fark daha da belirginleÅŸiyor; aÅŸaÄŸÄ±daki kÄ±yaslamada da gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gibi.

Raspberry Pi 5 gibi hafif bir donanÄ±mda bile QuestDB, daha gÃ¼Ã§lÃ¼ donanÄ±mlardaki rakiplerinden daha iyi performans gÃ¶steriyor:


<img width="872" height="623" alt="image" src="https://github.com/user-attachments/assets/9a8118f9-00a8-4cb0-8445-07360c99ac19" />

**Resimlerin kaynakÃ§asÄ± https://questdb.com/docs/why-questdb/**


### QuestDB'nin tek veritabanÄ± Ã¶zelliÄŸi
QuestDB, her Ã¶rnek iÃ§in tek bir veritabanÄ±na sahiptir . PostgreSQL ve diÄŸer veritabanÄ± motorlarÄ±nÄ±n aksine, bir Ã¶rnekte birden fazla veritabanÄ± veya birden fazla ÅŸema bulunabilirken, QuestDB'de tek bir ad alanÄ±nda Ã§alÄ±ÅŸÄ±rsÄ±nÄ±z.

VarsayÄ±lan veritabanÄ±nÄ±n adÄ± qdb'dir ve bu, yapÄ±landÄ±rma aracÄ±lÄ±ÄŸÄ±yla deÄŸiÅŸtirilebilir. Ancak, standart bir SQL veritabanÄ±nÄ±n aksine, USE DATABASE komut vermenize gerek yoktur. BaÄŸlandÄ±ktan sonra, hemen sorgulamaya ve veri eklemeye baÅŸlayabilirsiniz.


## Åema oluÅŸturma:
**Ã–nerilen yaklaÅŸÄ±m**
Bir ÅŸema oluÅŸturmanÄ±n en kolay yolu Web Konsolunu kullanmak veya ÅŸu SQL komutlarÄ±nÄ± gÃ¶ndermektir:
- REST API ( CREATE TABLE ifadeler)
- PostgreSQL kablolu protokol istemcileri


**Accessing the Web Console**
Web Console will be available at http://[server-address]:9000. When running locally, this will be http://localhost:9000.
<img width="1061" height="602" alt="image" src="https://github.com/user-attachments/assets/861a55ca-68d7-41e0-bfb8-555d08922756" />
### Web console ekranÄ± bÃ¶lÃ¼mleri ve iÅŸlevleri
- **Code Editor:** Kod DÃ¼zenleyicisi, sÃ¶zdizimi vurgulama, otomatik tamamlama ve hata izleme gibi Ã¶zelliklerle SQL sorgularÄ± yazÄ±p Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz yerdir. SeÃ§ime gÃ¶re sorgu yÃ¼rÃ¼tme, Ã§oklu sorgu yÃ¼rÃ¼tme ve sorgu planlamayÄ± destekler.
- **Metrics View:** Metrik GÃ¶rÃ¼nÃ¼mÃ¼, QuestDB Ã¶rneÄŸiniz iÃ§in gerÃ§ek zamanlÄ± izleme ve telemetri yetenekleri saÄŸlar. VeritabanÄ± performansÄ±nÄ±, WAL iÅŸlemlerini ve tabloya Ã¶zgÃ¼ metrikleri izlemek iÃ§in etkileÅŸimli grafikler ve araÃ§lar gÃ¶rÃ¼ntÃ¼ler.
- **Schema Explorer:** Åema Gezgini , tablolarÄ± ve somutlaÅŸtÄ±rÄ±lmÄ±ÅŸ gÃ¶rÃ¼nÃ¼mleri keÅŸfetmek iÃ§in bir gezinme merkezidir. Veri tÃ¼rlerini iÃ§eren sÃ¼tunlar, depolama yapÄ±landÄ±rmasÄ± (bÃ¶lÃ¼mlendirme ve WAL durumu) ve somutlaÅŸtÄ±rÄ±lmÄ±ÅŸ gÃ¶rÃ¼nÃ¼mler iÃ§in temel tablolar dahil olmak Ã¼zere her veritabanÄ± nesnesi hakkÄ±nda ayrÄ±ntÄ±lÄ± bilgi saÄŸlar.
- **Result Grid:** SonuÃ§ Tablosu, sorgu sonuÃ§larÄ±nÄ±zÄ± veri gezinme, dÄ±ÅŸa aktarma ve gÃ¶rselleÅŸtirme Ã¶zellikleriyle etkileÅŸimli bir tablo biÃ§iminde gÃ¶rÃ¼ntÃ¼ler.
- **Query Log:** Sorgu GÃ¼nlÃ¼ÄŸÃ¼, sorgu yÃ¼rÃ¼tme durumunu ve performans Ã¶lÃ§Ã¼mlerini izleyerek gerÃ§ek zamanlÄ± geri bildirim saÄŸlar ve son iÅŸlemlerin geÃ§miÅŸini tutar. SorgularÄ±nÄ±zÄ± optimize etmenize yardÄ±mcÄ± olmak iÃ§in yÃ¼rÃ¼tme sÃ¼relerini, satÄ±r sayÄ±larÄ±nÄ± ve ayrÄ±ntÄ±lÄ± hata bilgilerini gÃ¶sterir.
- **Import CSV** CSV Ä°Ã§e Aktarma arayÃ¼zÃ¼ , otomatik ÅŸema algÄ±lama, esnek yapÄ±landÄ±rma seÃ§enekleri ve ayrÄ±ntÄ±lÄ± ilerleme takibi ile CSV dosyalarÄ±nÄ± QuestDB'ye yÃ¼klemenize ve iÃ§e aktarmanÄ±za olanak tanÄ±r. Ä°Ã§e aktarma sÃ¼reci Ã¼zerinde tam kontrole sahip olarak yeni tablolar oluÅŸturabilir veya mevcut tablolara ekleme yapabilirsiniz.


**GRAFANA**: Verileri gÃ¶rselleÅŸtirmek ve zaman serisi veri analizini etkinleÅŸtirmek iÃ§in kullanÄ±lan popÃ¼ler bir gÃ¶zlemlenebilirlik ve izleme uygulamasÄ±dÄ±r. 


## Rest API
QuestDB REST API, standart HTTP Ã¶zelliklerine dayanÄ±r ve hazÄ±r HTTP istemcileri tarafÄ±ndan anlaÅŸÄ±lÄ±r. QuestDB ile etkileÅŸim kurmanÄ±n basit bir yolunu sunar ve Ã§oÄŸu programlama diliyle uyumludur. API iÅŸlevleri URL'ye tam olarak baÄŸlÄ±dÄ±r ve argÃ¼man olarak sorgu parametrelerini kullanÄ±r.

**Mevcut yÃ¶ntemler**
### /imp (Import data) for importing data from .CSV files.
Tablo biÃ§imindeki metin verilerini doÄŸrudan bir tabloya aktarÄ±r. Ä°steÄŸe baÄŸlÄ± baÅŸlÄ±klarla CSV, TAB ve boru ( ) ile ayrÄ±lmÄ±ÅŸ girdileri destekler . Veri boyutu konusunda herhangi bir kÄ±sÄ±tlama yoktur. Veri tÃ¼rleri ve yapÄ±larÄ±, ek yapÄ±landÄ±rmaya gerek kalmadan otomatik olarak algÄ±lanÄ±r.

**Ã–rnek kullanÄ±m:**
```bash
curl.exe -F "data=@C:\Users\hilal\OneDrive\MasaÃ¼stÃ¼\QuestDbDemo\weather.csv" "http://localhost:9000/imp?overwrite=true&name=new_table"

#User defined schema
curl.exe -F "schema=[{\"name\":\"temp\",\"type\":\"DOUBLE\"},{\"name\":\"humidity\",\"type\":\"INT\"},{\"name\":\"city\",\"type\":\"STRING\"}]" -F "data=@C:\Users\hilal\OneDrive\MasaÃ¼stÃ¼\QuestDbDemo\weather.csv" "http://localhost:9000/imp?overwrite=true&name=new_table"

```


### /exec to execute a SQL statement.
SQL INSERT Query, GiriÅŸ noktasÄ± bir SQL sorgusu alÄ±r ve sonuÃ§larÄ± JSON olarak dÃ¶ndÃ¼rÃ¼r. Bunu hÄ±zlÄ± SQL eklemeleri iÃ§in de kullanabiliriz, ancak SQL enjeksiyonu sorunlarÄ±ndan kaÃ§Ä±nmak iÃ§in gerekli olan parametreli sorgular iÃ§in destek olmadÄ±ÄŸÄ±nÄ± unutmayÄ±n. YÃ¼ksek performanslÄ± eklemelere ihtiyacÄ±nÄ±z varsa **InfluxDB SatÄ±r ProtokolÃ¼nÃ¼** tercih edin.

**Ã–rnek kullanÄ±m:**


```bash
# Tablo OluÅŸturma (CMD)
curl.exe -G ^
  --data-urlencode "query=CREATE TABLE IF NOT EXISTS trades(name STRING, value INT)" ^
  "http://localhost:9000/exec"


# SatÄ±r Ekleme
curl -G ^
  --data-urlencode "query=INSERT INTO trades VALUES('abc', 123456)" ^
  http://localhost:9000/exec
```

  
### /exp to Export Data.
Bu uÃ§ nokta, URL kodlu sorgularÄ± geÃ§irmenize olanak tanÄ±r ancak istek gÃ¶vdesi, JSON'un aksine kaydedilip yeniden kullanÄ±lmak Ã¼zere tablo biÃ§iminde dÃ¶ndÃ¼rÃ¼lÃ¼r. VeritabanÄ±nÄ± bir SQL select sorgusu ile sorgulamaya ve sonuÃ§larÄ± CSV olarak almaya olanak tanÄ±r. SonuÃ§larÄ± JSON formatÄ±nda almak iÃ§in /exec kullanÄ±rÄ±z. 

```bash
# Ã–nce weather tablosu oluÅŸturulabilir csv'den:

curl.exe -F "data=@C:\Users\hilal\OneDrive\MasaÃ¼stÃ¼\QuestDbDemo\weather.csv" "http://localhost:9000/imp?overwrite=true&name=weather"

# ArdÄ±ndan dÄ±ÅŸa aktarma iÅŸlemi yapÄ±labilir:

curl.exe -G ^
  --data-urlencode "query=SELECT temp, humidity, city FROM weather" ^
  --data-urlencode "limit=5" ^
  "http://localhost:9000/exp"

```


### Authentication(RBAC(Role-based Access Control))

#### REST API supports two authentication types:
- HTTP basic authentication
- Token-based authentication

Ä°lk kimlik doÄŸrulama tÃ¼rÃ¼ Ã§oÄŸunlukla web tarayÄ±cÄ±larÄ± tarafÄ±ndan desteklenir. Ancak, kullanÄ±cÄ± kimlik bilgilerini bir baÅŸlÄ±kta programatik olarak da uygulayabilirsiniz.(Authorization: Basic)


```csharp

# VeritabanÄ±nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve SQL sorgularÄ±nÄ± alÄ±p cevap verdiÄŸini gÃ¶sterir. Basic Auth kullanÄ±yoruz. Yani kullanÄ±cÄ± adÄ± ve ÅŸifreyi base64 ile encode edip HTTP headerâ€™a ekliyoruz.

curl -G --data-urlencode "query=SELECT 1;" ^
    -u "my_user:my_password" ^
    http://localhost:9000/exec
```

Ä°kinci kimlik doÄŸrulama tÃ¼rÃ¼, bir REST API belirtecinin bir baÅŸlÄ±kta belirtilmesini gerektirir  (Authorization: Bearer header)
```charp

# KullanÄ±cÄ± adÄ± ve ÅŸifre yerine tek seferlik veya uzun Ã¶mÃ¼rlÃ¼ token ile yetki veriyor

curl -G --data-urlencode "query=SELECT 1;" ^
    -H "Authorization: Bearer qt1cNK6s2t79f76GmTBN9k7XTWm5wwOtF7C0UBxiHGPn44" ^
    http://localhost:9000/exec

```

## PostgreSQL kablolu protokol istemcileri
### PostgreSQL ve PGWire

QuestDB, veri giriÅŸi iÃ§in Postgres Wire ProtokolÃ¼nÃ¼ (PGWire) destekler. **C# ile kullanacaÄŸÄ±mÄ±z zamanlarda da PGWire ile baÄŸlanacaÄŸÄ±z**. PGWire (Postgres Wire ProtokolÃ¼) PostgreSQL'in istemci-sunucu iletiÅŸim protokolÃ¼dÃ¼r. Sorgulama ve veri Ã§Ä±kÄ±ÅŸÄ± iÃ§in QuestDB, PostgreSQL protokolÃ¼yle uyumludur. Bu, QuestDB ile favori PostgreSQL istemcinizi veya sÃ¼rÃ¼cÃ¼nÃ¼zÃ¼ kullanabileceÄŸiniz anlamÄ±na gelir. PGWire arayÃ¼zÃ¼, Ã¶ncelikle QuestDB'den veri sorgulamak iÃ§in Ã¶nerilir.

**Not:** PostgreSQL depolama modeli QuestDB'den temel olarak farklÄ±dÄ±r. SonuÃ§ olarak PostgreSQL iÃ§in var olan bazÄ± Ã¶zellikler QuestDB'de bulunmamaktadÄ±r.


### PGWire Ä°stemcisine Genel BakÄ±ÅŸ:
QuestDB, istemcilerin PostgreSQL istemci kitaplÄ±klarÄ±nÄ± kullanarak QuestDB'ye baÄŸlanmasÄ±nÄ± saÄŸlamak iÃ§in PostgreSQL kablolu protokolÃ¼nÃ¼ (PGWire) kullanÄ±r. Bu, mevcut PostgreSQL istemcilerini ve kitaplÄ±klarÄ±nÄ± kullanmanÄ±za olanak tanÄ±dÄ±ÄŸÄ± iÃ§in QuestDB'yi kullanmaya baÅŸlamak iÃ§in harika bir yoldur. 

#### Sorgulama ve veri arayÃ¼zÃ¼
PGWire arayÃ¼zÃ¼, Ã¶ncelikle QuestDB'den veri sorgulamak iÃ§in Ã¶nerilir. Veri alÄ±mÄ±, Ã¶zellikle yÃ¼ksek verimli senaryolar iÃ§in QuestDB, InfluxDB Hat ProtokolÃ¼'nÃ¼ (ILP) destekleyen istemcilerinin kullanÄ±lmasÄ±nÄ± Ã¶nerir . Bu istemciler, hÄ±zlÄ± veri giriÅŸi iÃ§in optimize edilmiÅŸtir.


#### Zaman dalgasÄ± iÅŸleme
QuestDB, tÃ¼m zaman damgalarÄ±nÄ± dahili olarak UTC(Coordinated Universal Time) olarak depolar . Ancak, zaman damgalarÄ±nÄ± PGWire protokolÃ¼ Ã¼zerinden iletirken QuestDB bunlarÄ± "TIMESTAMP WITHOUT TIMEZONE" olarak gÃ¶sterir. Bu durum, istemci kÃ¼tÃ¼phanelerinin bu zaman damgalarÄ±nÄ± varsayÄ±lan olarak kendi yerel saat dilimlerinde yorumlamasÄ±na ve bu da olasÄ± karÄ±ÅŸÄ±klÄ±ÄŸa veya hatalÄ± veri gÃ¶sterimine yol aÃ§abilir. Dil Ã¶zelindeki kÄ±lavuzlarÄ±mÄ±z, istemcinizin bu zaman damgalarÄ±nÄ± UTC olarak doÄŸru ÅŸekilde yorumlayacak ÅŸekilde nasÄ±l yapÄ±landÄ±rÄ±lacaÄŸÄ±na dair ayrÄ±ntÄ±lÄ± Ã¶rnekler sunar.

Mevcut davranÄ±ÅŸ ÅŸu an iyileÅŸtirilmeye Ã§alÄ±ÅŸÄ±lÄ±yor. Bu arada, zaman damgalarÄ±nÄ±n tutarlÄ± bir ÅŸekilde iÅŸlenmesini saÄŸlamak iÃ§in istemci kitaplÄ±ÄŸÄ±nÄ±zdaki saat dilimini UTC olarak ayarlamanÄ±zÄ± Ã¶neririz.

**QuestDB CSV Import â€“ Timestamp ve Partition KullanÄ±mÄ±**

#### 1. CSV DosyasÄ±

CSVâ€™de timestamp kolonunu **ISO8601 UTC formatÄ±nda** veya **epoch milisaniye** ile saÄŸlamalÄ±sÄ±nÄ±z:

```csv
ts,temp,humidity,city
2025-09-16T10:00:00Z,24.5,40,Antalya
2025-09-16T11:00:00Z,26.1,38,Antalya
2025-09-16T12:00:00Z,27.3,35,Antalya
```
- Not: Z UTC (Coordinated Universal Time) anlamÄ±na gelir.

#### 2. CSVâ€™yi QuestDBâ€™ye Import Etme

- /imp endpointâ€™i ile import ederken timestamp ve partitionBy parametrelerini kullanÄ±n:
curl.exe -F "data=@C:\QuestDbDemo\weather.csv" "http://localhost:9000/imp?overwrite=true&name=weather&timestamp=ts&partitionBy=MONTH"

#### BÃ–YLECE:
- QuestDB timestampâ€™leri her zaman UTC olarak depolar

- Ä°stemci tarafÄ±nda timestampâ€™leri UTC olarak yorumlayÄ±n

- BÃ¶ylece saat farkÄ± veya yanlÄ±ÅŸ veri gÃ¶sterimi olmaz


#### YalnÄ±zca Ä°leri Ä°mleÃ§ler
QuestDB'nin imleÃ§leri yalnÄ±zca ileriye yÃ¶neliktir ve bu, PostgreSQL'in kaydÄ±rÄ±labilir imleÃ§ desteÄŸinden (Ã§ift yÃ¶nlÃ¼ gezinme ve rastgele satÄ±r eriÅŸimi saÄŸlar) farklÄ±dÄ±r. QuestDB ile sorgu sonuÃ§larÄ±nda baÅŸtan sona sÄ±rayla gezinebilirsiniz, ancak geriye gidemez veya belirli satÄ±rlara atlayamazsÄ±nÄ±z. KaydÄ±rÄ±labilir tÃ¼rler iÃ§in aÃ§Ä±k DECLARE CURSOR ifadeleri veya ters yÃ¶nde getirme gibi iÅŸlemler (Ã¶rneÄŸin, Ã‡alÄ±ÅŸma AlanÄ± BACKWARD) desteklenmez.
Bu sÄ±nÄ±rlama, kaydÄ±rÄ±labilir imleÃ§ Ã¶zelliklerine dayanan istemci kitaplÄ±klarÄ±nÄ± etkileyebilir. Ã–rneÄŸin, Python'Ä±n psycopg2 sÃ¼rÃ¼cÃ¼sÃ¼ bu tÃ¼r iÅŸlemleri denediÄŸinde sorunlarla karÅŸÄ±laÅŸabilir. En iyi uyumluluk iÃ§in sÃ¼rÃ¼cÃ¼leri seÃ§in veya mevcut sÃ¼rÃ¼cÃ¼leri, Python'Ä±n asyncpg sÃ¼rÃ¼cÃ¼sÃ¼ gibi yalnÄ±zca ileri imleÃ§leri kullanacak ÅŸekilde yapÄ±landÄ±rÄ±n.




### KullanÄ±m SenaryolarÄ±
- Time-series analytics iÃ§in QuestDB kullanÄ±mÄ±

- Mevcut PostgreSQL tool'larÄ± ile QuestDB'ye eriÅŸim

- High-throughput data ingestion ve analiz



### List of supported features:
- Sorgulama (tÃ¼m tipler hariÃ§ BLOB)
- BaÄŸlama parametreleriyle hazÄ±rlanmÄ±ÅŸ ifadeler
- INSERT baÄŸlama parametreli ifadeler
- UPDATE baÄŸlama parametreli ifadeler
- DDL yÃ¼rÃ¼tme
- Toplu ekler
- DÃ¼z kimlik doÄŸrulama


### List of unsupported features
- SSL
- Remote file upload (COPY from stdin)
- DELETE statements
- BLOB transfer


### CRUD -> create/read/update/delete  -> YukarÄ±daki kendi sitesinden alÄ±ntÄ± Ã¶zellik destekleri var.

- **CREATE ve READ var**
- **UPDATE**: QuestDB UPDATE desteklemez. Tek yol: yanlÄ±ÅŸ kaydÄ± silip (veya tabloyu truncate edip), doÄŸru veriyi yeniden insert etmek. Yani klasik anlamda update yok
- **DELETE**: QuestDBâ€™de DELETE sadece timestamp (designated timestamp) alanÄ± ile Ã§alÄ±ÅŸÄ±r. DELETE WHERE value = 123.45 gibi non-time sÃ¼tunlarÄ±nda Ã§alÄ±ÅŸmaz. KÄ±saca, var ama sadece ts Ã¼zerinden veya TRUNCATE ile diyebiliriz.



## ILP ProtokolÃ¼ ile Åema otomatik oluÅŸturma
Influx Line Protocol (ILP) kullanÄ±ldÄ±ÄŸÄ±nda , QuestDB gelen verilere gÃ¶re otomatik olarak tablolar ve sÃ¼tunlar oluÅŸturur.Bu Ã¶zellik, InfluxDB'den geÃ§iÅŸ yapan veya InfluxDB istemci kÃ¼tÃ¼phaneleri ya da Telegraf gibi araÃ§lar kullanan kullanÄ±cÄ±lar iÃ§in kullanÄ±ÅŸlÄ±dÄ±r , Ã§Ã¼nkÃ¼ Ã¶nceden tanÄ±mlanmÄ±ÅŸ ÅŸemalar olmadan verileri doÄŸrudan QuestDB'ye gÃ¶nderebilirler. Ancak bunun bazÄ± sÄ±nÄ±rlamalarÄ± vardÄ±r:
- QuestDB, otomatik olarak oluÅŸturulan tablolara ve sÃ¼tunlara varsayÄ±lan ayarlarÄ± uygular (Ã¶rneÄŸin, bÃ¶lÃ¼mlendirme, sembol kapasitesi ve veri tÃ¼rleri).
- BÃ¶lÃ¼mlemeyi veya sembol kapasitesini daha sonra deÄŸiÅŸtiremezsiniz .
- Veri tÃ¼rÃ¼nÃ¼ otomatik olarak oluÅŸturamazsÄ±nÄ±z IPv4. Bir IP adresini dize olarak gÃ¶ndermek bir sÃ¼tun oluÅŸturacaktÄ±r VARCHAR.
SÃ¼tun otomatik oluÅŸturmayÄ± yapÄ±landÄ±rma yoluyla devre dÄ±ÅŸÄ± bÄ±rakabilirsiniz . QuestDB, verileri almak iÃ§in InfluxDB Hat ProtokolÃ¼nÃ¼ uygular. InfluxDB Hat ProtokolÃ¼ yalnÄ±zca veri alÄ±mÄ± iÃ§indir Her ILP istemci kÃ¼tÃ¼phanesinin ayrÄ±ca kendi dil Ã¶zelinde dokÃ¼mantasyon seti vardÄ±r. Bu destekleyici belge, mÃ¼ÅŸteri seÃ§imi ve ilk yapÄ±landÄ±rmada yardÄ±mcÄ± olmak iÃ§in genel bir bakÄ±ÅŸ saÄŸlar.






## QuestDB and C#

### Performans Optimizasyonu Ä°Ã§in En Ä°yi Uygulamalar

- Otomatik Flush AyarlarÄ±: Veri gÃ¶nderimi sÄ±rasÄ±nda otomatik flush ayarlarÄ±nÄ± yapÄ±landÄ±rarak, belirli bir satÄ±r sayÄ±sÄ±na ulaÅŸÄ±ldÄ±ÄŸÄ±nda veya belirli bir zaman diliminde verilerin gÃ¶nderilmesini saÄŸlayabilirsiniz. 

- Veri Modelleme: Zaman damgasÄ± (timestamp) kullanÄ±mÄ± ve semboller (symbols) gibi veri modelleme teknikleriyle sorgu performansÄ±nÄ± artÄ±rabilirsiniz. 

- Sorgu Optimizasyonu: SorgularÄ±nÄ±zda LATEST ON gibi QuestDB'ye Ã¶zgÃ¼ SQL komutlarÄ±nÄ± kullanarak, en son verileri hÄ±zlÄ± bir ÅŸekilde alabilirsiniz


QuestDB doÄŸrudan C# iÃ§in Ã¶zel bir resmi client kÃ¼tÃ¼phanesi sunmaz. Ancak baÄŸlantÄ± yollarÄ± var. C# tarafÄ±nda en yaygÄ±n PostgreSQL kÃ¼tÃ¼phanesi Npgsqlâ€™dir. QuestDB de Postgres protokolÃ¼nÃ¼ konuÅŸtuÄŸu iÃ§in doÄŸrudan kullanÄ±labilir. **AdÄ±m adÄ±m kullanmaya baÅŸlayalÄ±m**:



#### 1- Docker Desktop bilgisayarÄ±nÄ±zda varsa aÃ§Ä±n. Bu sayede bilgisayarÄ±nÄ±zda Docker'Ä± Ã§alÄ±ÅŸtÄ±rmÄ±ÅŸ olacaksÄ±nÄ±z.
#### 2- Komut isteminde bu komutu Ã§alÄ±ÅŸtÄ±rarak Docker'Ä± baÅŸlatÄ±n

```bash
docker run -p 9000:9000 -p 8812:8812 -p 9009:9009 questdb/questdb:latest
```


#### KalÄ±cÄ± kaydetme iÃ§in
```bash
docker run -d --name questdb -p 9000:9000 -p 8812:8812 -p 9009:9009 -v C:\questdb_data:/var/lib/questdb/db -v C:\QuestDbDemo:/csv questdb/questdb:latest
```


#### 3- ArdÄ±ndan proje dizininize gidin ve paket eklemelerini yapÄ±n.

```bash
dotnet add package Npgsql
```

### Program.cs dosyasÄ±na bu kodu kopyalayÄ±n, QuestDB ile baÄŸlantÄ± saÄŸlarÄ±z bu kod ile.

```bash
using Npgsql;

string connString = "Host=localhost;Port=8812;Username=admin;Password=quest;Database=qdb";

using var conn = new NpgsqlConnection(connString);
conn.Open();
Console.WriteLine("QuestDB baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!");
```

### CRUD mimarisini karÅŸÄ±layan C# kod Ã¶rneÄŸi:

```bash

using System;
using Npgsql;
using NpgsqlTypes;

class Program
{
    static void Main(string[] args)
    {
        var connString = "Host=127.0.0.1;Port=8812;Username=admin;Password=quest;Database=qdb";

        using var conn = new NpgsqlConnection(connString);
        conn.Open();

        Console.WriteLine("QuestDB baÄŸlantÄ±sÄ± baÅŸarÄ±lÄ±!");

        // Epoch millis
        long tsMillis = DateTimeOffset.UtcNow.ToUnixTimeMilliseconds();

        // INSERT = CREATE
        using (var cmd = new NpgsqlCommand("INSERT INTO my_table (ts, value) VALUES (@ts, @val)", conn))
        {
            cmd.Parameters.Add("@ts", NpgsqlDbType.Bigint).Value = tsMillis;
            cmd.Parameters.Add("@val", NpgsqlDbType.Double).Value = 123.45;

            int rows = cmd.ExecuteNonQuery();
            Console.WriteLine($"{rows} satÄ±r eklendi.");
        }


        // DELETE = Truncate ile (TamamÄ±nÄ± siler)
        using (var cmd = new NpgsqlCommand("TRUNCATE TABLE my_table", conn)) // DosyanÄ±n tamamÄ±nÄ± temizleme
        {
            cmd.ExecuteNonQuery();
            Console.WriteLine("Tablo temizlendi.");
        }

        // SELECT Ã¶rneÄŸi (timestamp'i long olarak alÄ±yoruz) = READ
        using (var cmd = new NpgsqlCommand("SELECT cast(ts as long), value FROM my_table LIMIT 5", conn))
        using (var reader = cmd.ExecuteReader())
        {
            while (reader.Read())
            {
                long epochMillis = reader.GetInt64(0);
                DateTime tsValue = DateTimeOffset.FromUnixTimeMilliseconds(epochMillis).UtcDateTime;

                double val = reader.GetDouble(1);

                Console.WriteLine($"ts={tsValue:O}, value={val}");
            }
        }
    }
}

```


### QuestDBâ€™nin daha Ã¶nce bahsettiÄŸimiz REST API (port 9000) Ã¼zerinden sorgu gÃ¶nderebiliriz. C#â€™ta bunu `HttpClient` kullanarak yapabiliriz. Ã–rnek:

```csharp
using System;
using System.Net.Http;
using System.Threading.Tasks;

class Program
{
    static async Task Main()
    {
        using var client = new HttpClient();

        string query = "SELECT * FROM weather LIMIT 5";
        string url = "http://localhost:9000/exec?query=" + Uri.EscapeDataString(query);

        var response = await client.GetStringAsync(url);
        Console.WriteLine(response);
    }
}

```
Bu yÃ¶ntem JSON dÃ¶ndÃ¼rÃ¼r, sen de JSON parse ederek C# objelerine dÃ¶nÃ¼ÅŸtÃ¼rebilirsin.



### QuestDB'nin, InfluxDB line protocol ile veri kabul ettiÄŸini Ã¶ÄŸrenmiÅŸtik. Bu durumda C#â€™ta UDP/TCP soketi aÃ§Ä±p metin formatÄ±nda veri gÃ¶nderebilirsin.(Line Protocol (UDP/TCP ile Veri Yazma) (Ã–rnekteki UDP))

### Ã–rnek: AmacÄ±mÄ±z C# kullanarak bir sensÃ¶r verisini UDP Ã¼zerinden QuestDBâ€™ye (veya Line Protocol kabul eden bir veritabanÄ±na) gÃ¶ndermek.

 ```csharp
using System.Net.Sockets;
using System.Text;

class Program
{
    static void Main()
    {
        using var udpClient = new UdpClient();
        string line = "sensors,location=room1 value=25.3 " + DateTimeOffset.UtcNow.ToUnixTimeMilliseconds() + "000000";
        byte[] data = Encoding.UTF8.GetBytes(line);

        udpClient.Send(data, data.Length, "localhost", 9009);
        Console.WriteLine("Data sent to QuestDB via Line Protocol");
    }
}
```

Burada veriler Ã§ok hÄ±zlÄ± ÅŸekilde QuestDBâ€™ye yazÄ±labilir.


### DOTNET Client

- dotnet add package net-questdb-client

### TCP Ã¼zerinden kimlik doÄŸrulama gerekiyorsa, ek olarak ÅŸu paketi de kurmanÄ±z gerekir:

- dotnet add package net-questdb-client-tcp-auth

### Temel kimlik doÄŸrulama

- using var sender = Sender.New("http::addr=localhost:9000;username=admin;password=quest;"); 

### Token kimlik doÄŸrulama

- using var sender = Sender.New("http::addr=localhost:9000;username=admin;token=<token>");

###  TCP kimlik doÄŸrulama

- using var sender = Sender.New("tcp::addr=localhost:9009;username=admin;token=<token>");



### Temel ekleme (kimlik doÄŸrulamasÄ± olmadan)

#### WAL NEDÄ°R? (WAL = Write-Ahead Log)
- VeritabanÄ± teknolojilerinde Ã§ok yaygÄ±n bir kavramdÄ±r.

- Normal tabloda: Veriler doÄŸrudan tabloya yazÄ±lÄ±r.WAL tabloda: Ã–nce bir log (gÃ¼nlÃ¼k) dosyasÄ±na yazÄ±lÄ±r, sonra arka planda tabloya iÅŸlenir.

**Bu sayede:**

- Yazma Ã§ok hÄ±zlÄ± olur (Ã§Ã¼nkÃ¼ sadece append log yazÄ±yorsun).

- DayanÄ±klÄ±lÄ±k artar (Ã§Ã¼nkÃ¼ logâ€™dan recovery yapÄ±labilir).

- Concurrent ingestion (Ã§oklu thread/process aynÄ± tabloya aynÄ± anda yazabilir).


#### AvantajlarÄ±

- Ã‡ok yÃ¼ksek ingestion hÄ±zÄ± (milyonlarca row/sn).

- Asenkron commit â†’ yazma hÄ±zÄ± artar.

- Crash sonrasÄ± recovery daha gÃ¼venilir.

#### DezavantajlarÄ±

- Biraz daha fazla disk kullanÄ±r (Ã§Ã¼nkÃ¼ log dosyalarÄ± tutulur).

- â€œÄ°lk yazÄ±mâ€ sonrasÄ±nda veri arka planda iÅŸleneceÄŸi iÃ§in, bazÄ± edge caseâ€™lerde hemen sorgulanabilir olmayabilir (ama QuestDB bunu hÄ±zlÄ± senkronize eder).



#### WALL yapÄ±sÄ± ile tablo oluÅŸturuyoruz.

```bash
DROP TABLE trades;

CREATE TABLE trades (
    symbol SYMBOL,
    side SYMBOL,
    price DOUBLE,
    amount DOUBLE,
    ts TIMESTAMP
) TIMESTAMP(ts) PARTITION BY DAY WAL;
```
#### ArdÄ±ndan C# tarafÄ±nda bu kodu Ã§alÄ±ÅŸtÄ±rarak verileri ekleyebiliyoruz.

```csharp
using System;
using QuestDB;

using var sender =  Sender.New("http::addr=localhost:9000;");
await sender.Table("trades")
    .Symbol("symbol", "ETH-USD")
    .Symbol("side", "sell")
    .Column("price", 2615.54)
    .Column("amount", 0.00044)
    .AtNowAsync();
await sender.Table("trades")
    .Symbol("symbol", "BTC-USD")
    .Symbol("side", "sell")
    .Column("price", 39269.98)
    .Column("amount", 0.001)
    .AtNowAsync();
await sender.SendAsync();

```

#### Zaman damgalarÄ±, Ã¶zel otomatik temizleme, temel kimlik doÄŸrulama ve hata bildirimi iÃ§eren bir Ã¶rnek:

```charp

using QuestDB;
using System;
using System.Threading.Tasks;

class Program
{
    static async Task Main(string[] args)
    {
        using var sender = Sender.New(
          "http::addr=localhost:9000;username=admin;password=quest;auto_flush_rows=100;auto_flush_interval=1000;"
        );

        var now = DateTime.UtcNow;
        try
        {
            await sender.Table("trades")
                        .Symbol("symbol", "ETH-USD")
                        .Symbol("side", "sell")
                        .Column("price", 2615.54)
                        .Column("amount", 0.00044)
                        .AtAsync(now);

            await sender.Table("trades")
                        .Symbol("symbol", "BTC-USD")
                        .Symbol("side", "sell")
                        .Column("price", 39269.98)
                        .Column("amount", 0.001)
                        .AtAsync(now);

            await sender.SendAsync();

            Console.WriteLine("Data flushed successfully.");
        }
        catch (Exception ex)
        {
            Console.Error.WriteLine($"Error: {ex.Message}");
        }
    }
}
```


### Rest API + C# ile belirli bir tarih aralÄ±ÄŸÄ±nÄ± getirme ve sÃ¼resi:

```csharp

using System;
using System.Diagnostics;
using System.Net.Http;
using System.Threading.Tasks;

class Program
{
    static async Task Main()
    {
        var client = new HttpClient();


        var start = DateTime.UtcNow.AddDays(-30).ToString("yyyy-MM-dd HH:mm:ss");
        var end   = DateTime.UtcNow.ToString("yyyy-MM-dd HH:mm:ss");


        string sql = $"SELECT * FROM veriler WHERE tarih BETWEEN '{start}' AND '{end}' LIMIT 100";

        var url = $"http://10.141.2.7:6587/exec?query={Uri.EscapeDataString(sql)}";

        var sw = Stopwatch.StartNew();
        var response = await client.GetAsync(url);
        sw.Stop();

        Console.WriteLine($"HTTP sorgu sÃ¼resi: {sw.ElapsedMilliseconds} ms");

        if (response.IsSuccessStatusCode)
        {
            var content = await response.Content.ReadAsStringAsync();
            Console.WriteLine("SonuÃ§ Ã¶rneÄŸi:");
            Console.WriteLine(content);
        }
        else
        {
            Console.WriteLine($"Hata: {response.StatusCode}");
            var errContent = await response.Content.ReadAsStringAsync();
            Console.WriteLine(errContent);
        }
    }
}

```


### QuestDB'de doÄŸrudan `ALTER TABLE RENAME COLUMN` desteÄŸi yoktur. Bu nedenle sÃ¼tun adlarÄ±nÄ± deÄŸiÅŸtirmek iÃ§in tabloyu yeni isimlerle yeniden oluÅŸturmak gerekir.  AÅŸaÄŸÄ±daki adÄ±mlar `test6` tablosu iÃ§in Ã¶rneklenmiÅŸtir:


```sql

CREATE TABLE test6_new AS (
    SELECT 
        f0 AS id,
        f1 AS device_id,
        f2 AS temperature,
        f3 AS humidity,
        cast(f4 as TIMESTAMP) AS ts
    FROM test6
) TIMESTAMP(ts);



DROP TABLE test6;

RENAME TABLE test6_new TO test6;

SELECT count(*) FROM test6

```

### WAL yapÄ±sÄ±nda nasÄ±l tablo oluÅŸur? "PARTITION BY DAY WAL ekleriz tablo sonuna. Tabloyu oluÅŸtururken eklemek zorundayÄ±z, yoksa yeni tabloyu WALL ile aÅŸaÄŸÄ±daki ÅŸekilde oluÅŸturup mevcut tabloyu geÃ§iririz"

```sql
CREATE TABLE test6_new AS (
    SELECT 
        f0 AS id,
        f1 AS device_id,
        f2 AS temperature,
        f3 AS humidity,
        cast(f4 as TIMESTAMP) AS ts
    FROM test6
) TIMESTAMP(ts) PARTITION BY DAY WAL;
```



**SÄ±rasÄ±yla komutlarÄ± bu ÅŸekilde Ã§alÄ±ÅŸtÄ±rabiliriz. Bu sorgu ile yeni tabloda kayÄ±tlarÄ±n eksiksiz (count ile)taÅŸÄ±ndÄ±ÄŸÄ±nÄ± doÄŸrulayabiliriz.**



### Sorgular genel olarak 5 ms gibi kÄ±sa sÃ¼re almakta.

```sql
SELECT *
FROM test6
WHERE ts BETWEEN '2024-01-28T11:49:00.000Z' AND '2025-02-28T11:55:00.000Z';
```

```sql
SELECT *
FROM test6
WHERE device_id = 1
  AND ts BETWEEN '2025-02-28T11:49:00.000Z' AND '2025-02-28T12:00:00.000Z';
```


### SAMPLE BY ile zaman serisi verilerinde downsampling (Ã¶rnekleme) yapÄ±yoruz:

```sql
SELECT ts, min(temperature), max(temperature)
FROM test6
SAMPLE BY 1h;
```

```sql
SELECT ts, avg(temperature) AS avg_temp
FROM test6
SAMPLE BY 1m;
```
**Burada her 1 dakikalÄ±k pencere iÃ§in avg_temp hesaplanÄ±r.**


### WHERE IN ile birden fazla zaman aralÄ±ÄŸÄ±nda arama yaparÄ±z.

```sql
SELECT *
FROM test6
WHERE ts IN '2025-02-28T11:49:00.000Z;2025-02-28T12:00:00.000Z',
              '2025-03-01T10:00:00.000Z;2025-03-01T11:00:00.000Z';
```

### LATEST ON ile her cihaz iÃ§in en gÃ¼ncel kaydÄ± getiririz.

```sql
SELECT *
FROM test6
LATEST ON ts PARTITION BY device_id;
```

### ASOF JOIN ile zaman serisi tablolarÄ±nÄ± yakÄ±n zamana gÃ¶re joinleriz.

```sql
SELECT a.ts, a.temperature, b.data_id
FROM test6 a
ASOF JOIN veriler b;
```

**Burada test6â€™daki zaman damgasÄ±na en yakÄ±n veriler tablosundaki kayÄ±t eÅŸleÅŸir.**



### Materialized Views (MaddeleÅŸtirilmiÅŸ GÃ¶rÃ¼nÃ¼mler) ile  (Tablo WAL yapÄ±sÄ±nda olmak zorunda. Ã‡Ã¼nkÃ¼ materialized view gÃ¼ncel verileri takip edebilmek iÃ§in WAL Ã¶zelliÄŸine ihtiyaÃ§ duyuyor.)

```sql
CREATE MATERIALIZED VIEW avg_temp_1m AS
SELECT ts, avg(temperature) AS avg_temp
FROM test6
SAMPLE BY 1m;
```
**Ã–rneÄŸin sÄ±caklÄ±klarÄ±n dakikalÄ±k ortalamasÄ±nÄ± saklamak iÃ§in kullanÄ±rÄ±z.  MV sayesinde sÃ¼rekli hesap yapmak zorunda kalmayÄ±z â†’ sorgular Ã§ok daha hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r.**



### SAMPLE BY + Fill PolitikalarÄ±: QuestDBâ€™de eksik verileri doldurma Ã¶zelliÄŸi vardÄ±r:

```sql
SELECT ts, avg(temperature)
FROM test6
SAMPLE BY 1m FILL(LINEAR);
```


**Bu, zaman serilerinde eksik veri olduÄŸunda Ã§ok faydalÄ±.**

- FILL(NONE) â†’ boÅŸ bÄ±rakÄ±r

- FILL(PREV) â†’ Ã¶nceki deÄŸeri taÅŸÄ±r

- FILL(LINEAR) â†’ lineer interpolasyon yapar

- FILL(VALUE x) â†’ sabit deÄŸer atar


### Normalde bunu yaparÄ±z en gÃ¼ncel verileri almak iÃ§in fakat aÅŸaÄŸÄ±daki yÃ¶ntem daha hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r.

```sql
SELECT device_id, ts, temperature
FROM (
    SELECT device_id, ts, temperature,
           ROW_NUMBER() OVER (PARTITION BY device_id ORDER BY ts DESC) AS rn
    FROM test6
)
WHERE rn = 1;
```


### LATEST ON ts PARTITION BY key, QuestDBâ€™de zaman serisi tablolarÄ±nda, her grup iÃ§in en gÃ¼ncel satÄ±rÄ± almak iÃ§in kullanÄ±lÄ±r.

```sql
SELECT *
FROM test6
LATEST ON ts PARTITION BY device_id;
```

## ADO.NET + Dapper 


### PGWire portu olup olmadÄ±ÄŸÄ±nÄ± anlamak iÃ§in:


```sql
Test-NetConnection 10.141.2.7 -Port 6588 
```

#### Ã‡IKTIDA TcpTestSucceeded : True kÄ±smÄ± false ise deÄŸildir:

PS C:\Users\hilal> Test-NetConnection 10.141.2.7 -Port 6588


ComputerName     : 10.141.2.7
RemoteAddress    : 10.141.2.7
RemotePort       : 6588
InterfaceAlias   : Wi-Fi
SourceAddress    : 192.168.137.94
TcpTestSucceeded : True



### Gerekli paketler

```sql
dotnet add package Npgsql
dotnet add package Dapper
```

### Kod Ã¶rneÄŸi

```charp

using System;
using System.Threading.Tasks;
using System.Collections.Generic;
using Dapper;
using Npgsql;

namespace QuestDbDemo
{
    class Program
    {
        public class AvgTempRow
        {
            public string Ts { get; set; }
            public double AvgTemp { get; set; }
        }

        public class Measurement
        {
            public string Ts { get; set; }
            public int DeviceId { get; set; }
            public double Temperature { get; set; }
        }

        public class TempRangeRow
        {
            public string Ts { get; set; }
            public double MinTemp { get; set; }
            public double MaxTemp { get; set; }
        }

        static async Task Main(string[] args)
        {
            var connString = "Host=10.141.2.7;Port=6588;Username=admin;Password=quest;Database=qdb;SSL Mode=Disable;Pooling=true;Maximum Pool Size=50;CommandTimeout=30;TimeZone=UTC";
            
            await using var dataSource = NpgsqlDataSource.Create(connString);
            await using var conn = await dataSource.OpenConnectionAsync();

            Console.WriteLine("âœ… BaÄŸlantÄ± baÅŸarÄ±lÄ±!");

            try
            {
                // Mevcut sorgular
                await RunSampleByQuery(conn);
                await RunParameterizedQuery(conn);
                await RunLatestOnQuery(conn);

                Console.WriteLine("\n" + new string('-', 30) + "\n");
                Console.WriteLine("### Yeni Sorgu Ã–rnekleri ###");

                // Yeni eklenen sorgular
                await RunSampleByWithMinMaxQuery(conn);
                await RunLatestOnWithPartitionQuery(conn);
            }
            catch (Exception ex)
            {
                Console.WriteLine($"âŒ Hata: {ex.Message}");
                Console.WriteLine($"âŒ Stack Trace: {ex.StackTrace}");
            }
        }
        
        /// <summary>
        /// `SAMPLE BY` ile dakikalÄ±k ortalama sÄ±caklÄ±k sorgusu.
        /// </summary>
        private static async Task RunSampleByQuery(NpgsqlConnection conn)
        {
            var sqlAvg = "SELECT ts::text AS Ts, avg(temperature) AS AvgTemp FROM test6 SAMPLE BY 1m;";
            var avgRows = await conn.QueryAsync<AvgTempRow>(sqlAvg);
            Console.WriteLine("\n--- Avg Temperature SAMPLE BY 1m ---");
            foreach (var r in avgRows)
            {
                Console.WriteLine($"{r.Ts} -> {r.AvgTemp:F2}");
            }
        }

        /// <summary>
        /// Belirli cihaz ve zaman aralÄ±ÄŸÄ± iÃ§in parametreli sorgu.
        /// </summary>
       private static async Task RunParameterizedQuery(NpgsqlConnection conn)
{
    var sqlParams = @"
        SELECT 
            ts::text AS Ts,
            device_id AS DeviceId, 
            temperature AS Temperature
        FROM test6
        WHERE device_id = @DeviceId AND ts BETWEEN @From AND @To
        ORDER BY ts ASC
        LIMIT @Limit;";

    var parameters = new DynamicParameters();
    parameters.Add("@DeviceId", 1);
    parameters.Add("@Limit", 100);
    parameters.Add("@From", DateTime.Parse("2025-02-28T11:49:00Z").ToUniversalTime(), System.Data.DbType.DateTime);
    parameters.Add("@To", DateTime.Parse("2025-02-28T12:00:00Z").ToUniversalTime(), System.Data.DbType.DateTime);

    var measurements = await conn.QueryAsync<Measurement>(sqlParams, parameters);

    Console.WriteLine("\n--- Measurements for device 1 ---");
    foreach (var m in measurements)
    {
        Console.WriteLine($"{m.Ts} | device:{m.DeviceId} | temp:{m.Temperature:F2}");
    }
}

        /// <summary>
        /// Her cihaz iÃ§in en son Ã¶lÃ§Ã¼mÃ¼ getiren `LATEST ON` sorgusu.
        /// </summary>
        private static async Task RunLatestOnQuery(NpgsqlConnection conn)
        {
            var sqlLatest = @"
                SELECT 
                    ts::text AS Ts,
                    device_id AS DeviceId, 
                    temperature AS Temperature 
                FROM test6 
                LATEST ON ts 
                PARTITION BY device_id;";
            
            var latest = await conn.QueryAsync<Measurement>(sqlLatest);
            Console.WriteLine("\n--- Latest Measurements per Device ---");
            foreach (var l in latest)
            {
                Console.WriteLine($"{l.Ts} | device:{l.DeviceId} | temp:{l.Temperature:F2}");
            }
        }
        
        // --- Yeni eklenen metotlar ---

        /// <summary>
        /// `SAMPLE BY` ile saatlik en dÃ¼ÅŸÃ¼k ve en yÃ¼ksek sÄ±caklÄ±k sorgusu.
        /// </summary>
        private static async Task RunSampleByWithMinMaxQuery(NpgsqlConnection conn)
        {
            var sql = "SELECT ts::text AS Ts, min(temperature) AS MinTemp, max(temperature) AS MaxTemp FROM test6 SAMPLE BY 1h;";
            var tempRows = await conn.QueryAsync<TempRangeRow>(sql);

            Console.WriteLine("\n--- Min and Max Temperature SAMPLE BY 1h ---");
            foreach (var r in tempRows)
            {
                Console.WriteLine($"{r.Ts} -> Min: {r.MinTemp:F2}, Max: {r.MaxTemp:F2}");
            }
        }

        /// <summary>
        /// `LATEST ON` ile her cihaz iÃ§in en gÃ¼ncel veriyi getiren sorgu.
        /// </summary>
        private static async Task RunLatestOnWithPartitionQuery(NpgsqlConnection conn)
        {
            var sql = @"
                SELECT 
                    ts::text AS Ts,
                    device_id AS DeviceId, 
                    temperature AS Temperature
                FROM test6
                LATEST ON ts PARTITION BY device_id;";

            var latestMeasurements = await conn.QueryAsync<Measurement>(sql);

            Console.WriteLine("\n--- LATEST ON per device_id ---");
            foreach (var m in latestMeasurements)
            {
                Console.WriteLine($"{m.Ts} | device:{m.DeviceId} | temp:{m.Temperature:F2}");
            }
        }
    }
}

```


### SENDER API Kod Ã–rneÄŸi:

```charp

using System;
using System.Net.Http;
using System.Threading.Tasks;
using System.Collections.Generic;
using System.Text.Json;

namespace QuestDbHttpDemo
{
    class Program
    {
        public class AvgTempRow
        {
            public string? ts { get; set; }
            public double? avg_temp { get; set; }
        }

        public class Measurement
        {
            public string? ts { get; set; }
            public int? device_id { get; set; }
            public double? temperature { get; set; }
        }

        public class MinMaxTemp
        {
            public string? ts { get; set; }
            public double? min { get; set; }
            public double? max { get; set; }
        }

        static async Task Main(string[] args)
        {
            var baseUrl = "http://10.141.2.7:6587/exec"; 
            using var client = new HttpClient();

            Console.WriteLine("âœ… HTTP ile baÄŸlantÄ± hazÄ±r");

            try
            {
                await RunCountCheck(client, baseUrl);
                await RunSampleBy(client, baseUrl);
                await RunWhereRanges(client, baseUrl);
                await RunLatestOn(client, baseUrl);
                await RunAsofJoin(client, baseUrl);
                await RunMaterializedView(client, baseUrl);
                await RunFillPolicies(client, baseUrl);
            }
            catch (Exception ex)
            {
                Console.WriteLine($"âŒ Hata: {ex.Message}");
                Console.WriteLine($"âŒ Stack Trace: {ex.StackTrace}");
            }
        }

        // 1ï¸âƒ£ COUNT ile doÄŸrulama
        private static async Task RunCountCheck(HttpClient client, string baseUrl)
        {
            string sql = @"
                SELECT count(*) 
                FROM test6
                WHERE ts BETWEEN '2024-01-28T11:49:00.000Z' AND '2025-02-28T11:55:00.000Z';
            ";
            var result = await QueryAsync<Measurement>(client, baseUrl, sql);
            Console.WriteLine("\n--- Count Check ---");
            foreach (var r in result)
                Console.WriteLine($"Count: {r.temperature}");
        }

        // 2ï¸âƒ£ SAMPLE BY min & max
        private static async Task RunSampleBy(HttpClient client, string baseUrl)
        {
            string sql = "SELECT ts, min(temperature), max(temperature) FROM test6 SAMPLE BY 1h;";
            var result = await QueryAsync<MinMaxTemp>(client, baseUrl, sql);
            Console.WriteLine("\n--- SAMPLE BY 1h (min/max) ---");
            foreach (var r in result)
                Console.WriteLine($"{r.ts} -> min:{r.min} | max:{r.max}");
        }

        // 3ï¸âƒ£ WHERE IN
        private static async Task RunWhereRanges(HttpClient client, string baseUrl)
{
    // ğŸ”¹ Birden fazla zaman aralÄ±ÄŸÄ±nÄ± listeye ekliyoruz
    var ranges = new List<(string start, string end)>
    {
        ("2025-02-28T11:49:00.000Z", "2025-02-28T12:00:00.000Z"),
        ("2025-03-01T10:00:00.000Z", "2025-03-01T11:00:00.000Z"),
        ("2025-03-02T08:00:00.000Z", "2025-03-02T09:00:00.000Z") // Ã¶rnek ek aralÄ±k
    };

    // ğŸ”¹ SQL WHERE koÅŸulunu dinamik oluÅŸturuyoruz
    var whereConditions = new List<string>();
    foreach (var (start, end) in ranges)
    {
        whereConditions.Add($"(ts BETWEEN '{start}' AND '{end}')");
    }
    string whereClause = string.Join(" OR ", whereConditions);

    string sql = $@"
        SELECT *
        FROM test6
        WHERE {whereClause}
        ORDER BY ts ASC;
    ";

    var result = await QueryAsync<Measurement>(client, baseUrl, sql);
    Console.WriteLine("\n--- Dinamik WHERE RANGES ---");
    foreach (var r in result)
        Console.WriteLine($"{r.ts} | device:{r.device_id} | temp:{r.temperature}");
}


        // 4ï¸âƒ£ LATEST ON ts PARTITION BY device_id
        private static async Task RunLatestOn(HttpClient client, string baseUrl)
        {
            string sql = "SELECT * FROM test6 LATEST ON ts PARTITION BY device_id;";
            var result = await QueryAsync<Measurement>(client, baseUrl, sql);
            Console.WriteLine("\n--- Latest per Device ---");
            foreach (var r in result)
                Console.WriteLine($"{r.ts} | device:{r.device_id} | temp:{r.temperature}");
        }

        // 5ï¸âƒ£ ASOF JOIN
        private static async Task RunAsofJoin(HttpClient client, string baseUrl)
        {
            string sql = @"
                SELECT a.ts, a.temperature, b.device_id
                FROM test6 a
                ASOF JOIN test6 b;
            ";
            var result = await QueryAsync<Measurement>(client, baseUrl, sql);
            Console.WriteLine("\n--- ASOF JOIN ---");
            foreach (var r in result)
                Console.WriteLine($"{r.ts} | temp:{r.temperature} | device:{r.device_id}");
        }

        // 6ï¸âƒ£ MATERIALIZED VIEW (Ã¶rnek)
        private static async Task RunMaterializedView(HttpClient client, string baseUrl)
        {
            string sql = @"
                CREATE MATERIALIZED VIEW IF NOT EXISTS avg_temp_1m AS
                SELECT ts, avg(temperature) AS avg_temp
                FROM test6 SAMPLE BY 1m;
            ";
            await QueryAsync<AvgTempRow>(client, baseUrl, sql);
            Console.WriteLine("\nâœ… Materialized View oluÅŸturuldu (avg_temp_1m)");
        }

        // 7ï¸âƒ£ SAMPLE BY + FILL PolitikalarÄ±
        private static async Task RunFillPolicies(HttpClient client, string baseUrl)
        {
            string sql = "SELECT ts, avg(temperature) FROM test6 SAMPLE BY 1m FILL(LINEAR);";
            var result = await QueryAsync<AvgTempRow>(client, baseUrl, sql);
            Console.WriteLine("\n--- SAMPLE BY 1m FILL(LINEAR) ---");
            foreach (var r in result)
                Console.WriteLine($"{r.ts} -> {r.avg_temp}");
        }

        // ğŸ”¹ Generic sorgu metodu
        private static async Task<List<T>> QueryAsync<T>(HttpClient client, string baseUrl, string sql)
        {
            var url = baseUrl + "?query=" + Uri.EscapeDataString(sql);
            var response = await client.GetAsync(url);
            response.EnsureSuccessStatusCode();
            var json = await response.Content.ReadAsStringAsync();

            using var doc = JsonDocument.Parse(json);
            var rows = new List<T>();

            if (doc.RootElement.TryGetProperty("dataset", out var dataset))
            {
                var properties = typeof(T).GetProperties();
                foreach (var row in dataset.EnumerateArray())
                {
                    var obj = Activator.CreateInstance<T>();
                    for (int i = 0; i < row.GetArrayLength() && i < properties.Length; i++)
                    {
                        var prop = properties[i];
                        var val = row[i];

                        if (val.ValueKind == JsonValueKind.String)
                        {
                            prop.SetValue(obj, val.GetString());
                        }
                        else if (val.ValueKind == JsonValueKind.Number)
                        {
                            if (prop.PropertyType == typeof(double) || prop.PropertyType == typeof(double?))
                                prop.SetValue(obj, val.GetDouble());
                            else if (prop.PropertyType == typeof(int) || prop.PropertyType == typeof(int?))
                            {
                                if (val.ValueKind == JsonValueKind.Number)
                                    prop.SetValue(obj, val.GetInt32());
                                else if (val.ValueKind == JsonValueKind.String && int.TryParse(val.GetString(), out int intVal))
                                    prop.SetValue(obj, intVal);
                            }

                        }
                    }
                    rows.Add(obj);
                }
            }
            return rows;
        }
    }
}


```

**Bu kodda veriler fazla olduÄŸu iÃ§in kod hatalÄ± Ã§alÄ±ÅŸabilir.**


## QuestDB .NET KullanÄ±m YÃ¶ntemleri

| YÃ¶ntem             | Ã–zellikler                                                                 |
|--------------------|------------------------------------------------------------------------------|
| **Sender API**     | - Sadece **WAL tablolarÄ±** destekler <br> - Ã‡ok hÄ±zlÄ±, **real-time ingestion** iÃ§in tasarlanmÄ±ÅŸ |
| **ADO.NET + Dapper** | - Hem **WAL** hem **non-WAL** tablolarÄ±yla Ã§alÄ±ÅŸÄ±r <br> - Normal **SQL** yazabilirsin (`SELECT`, `INSERT`, `UPDATE`, `JOIN` vs.) <br> - ORM kolaylÄ±ÄŸÄ± saÄŸlar |


## QuestDB .NET KullanÄ±m YÃ¶ntemleri KarÅŸÄ±laÅŸtÄ±rma

| Ä°ÅŸlem TÃ¼rÃ¼                          | En Uygun YÃ¶ntem     | AÃ§Ä±klama |
|-------------------------------------|---------------------|----------|
| **INSERT (Ã§ok hÄ±zlÄ±, akÄ±ÅŸ)**        |  Sender API        | Line Protocol ile Ã§ok yÃ¼ksek throughput saÄŸlar. Ã–zellikle IoT, sensÃ¶r, log gibi sÃ¼rekli veri akÄ±ÅŸlarÄ±nda idealdir. |
| **INSERT (az miktar, normal)**      |  ADO.NET + Dapper  | KÃ¼Ã§Ã¼k hacimli veri eklemeleri iÃ§in uygundur. KullanÄ±mÄ± kolaydÄ±r ama Sender kadar hÄ±zlÄ± deÄŸildir. |
| **SELECT (arama, filtre, BETWEEN)** |  ADO.NET + Dapper  | PostgreSQL wire protocol Ã¼zerinden tam SQL sorgu desteÄŸi sunar. AralÄ±k sorgularÄ± iÃ§in en hÄ±zlÄ± ve gÃ¼venilir yÃ¶ntemdir. |
| **Analitik sorgular (GROUP BY, JOIN, ORDER)** |  ADO.NET + Dapper | SQL tam desteÄŸi olduÄŸu iÃ§in karmaÅŸÄ±k analizlerde tercih edilir. |
| **GerÃ§ek zamanlÄ± stream yazma**     |  Sender API        | GerÃ§ek zamanlÄ± veri ingestion iÃ§in en yÃ¼ksek performansÄ± saÄŸlar. |

---

### Ã–neri
- **Veri yazma (INSERT)** â†’ **Sender API** (yÃ¼ksek hacim iÃ§in).  
- **Veri okuma (SELECT, aralÄ±k sorgusu, analiz)** â†’ **ADO.NET + Dapper**.  

(QuestDB'ye import etme) YÃ¼kleme yÃ¶ntemleri: COPY FROM, REST API, Influx Line Protocol, PostgreSQL wire protokolÃ¼, Kafka/MQTT entegrasyonu.


# ğŸ“š KaynakÃ§a

- [QuestDB Demo](https://demo.questdb.io/index.html) â€“ Online demo ortamÄ±  
- [QuestDB Download](https://questdb.com/download/) â€“ QuestDB indirme sayfasÄ±  
- [QuestDB GitHub](https://github.com/questdb) â€“ ResmÃ® GitHub adresi  

## ğŸ”¹ CanlÄ± Dashboard Ã–rnekleri
- [Crypto Dashboard](https://questdb.com/dashboards/crypto/) â€“ CanlÄ± kripto verileri  
- [FX Orderbook Dashboard](https://questdb.com/dashboards/fx-orderbook/) â€“ CanlÄ± FX Orderbook verileri  

## ğŸ”¹ Grafana Entegrasyonu
- [Grafana Plugin (QuestDB Datasource)](https://grafana.com/grafana/plugins/questdb-questdb-datasource/)  
- [Grafana KullanÄ±mÄ± DokÃ¼mantasyon](https://questdb.com/docs/third-party-tools/grafana/)  
- [QuestDB Demo (GÃ¶rselleÅŸtirme)](https://demo.questdb.io/index.html)  

## ğŸ”¹ SQL & Veri YapÄ±larÄ±
- [QuestDB Veri Tipleri](https://questdb.com/docs/reference/sql/datatypes/)  
- [SQL Overview](https://questdb.com/docs/reference/sql/overview/#postgresql)  

## ğŸ”¹ Ingestion & API
- [ILP Protocol Overview](https://questdb.com/docs/reference/api/ilp/overview/)  

## ğŸ”¹ .NET / C# KullanÄ±mÄ±
- [QuestDB .NET Client](https://questdb.com/docs/clients/ingest-dotnet/)  
- [Medium YazÄ±sÄ±: QuestDB ile Zaman YolculuÄŸu (C#)](https://medium.com/@sumerburak/questdb-ile-zaman-yolculu%C4%9Funa-%C3%A7%C4%B1k%C4%B1yoruz-net-ile-e%C4%9Flenceli-bir-macera-c7bea81d4af1)  
